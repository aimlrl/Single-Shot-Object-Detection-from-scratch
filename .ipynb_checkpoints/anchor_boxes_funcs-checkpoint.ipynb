{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_anchor_boxes_scales(num_extra_layers=2):\n",
    "    \"\"\"This function generates different scales of anchor boxes for extra convolutional layers \n",
    "    added to the pretrained convolutional base of any pretrained network. We are assuming that we have \n",
    "    added one more layer on the top of pretrained convolutional base, therefore it will result in object \n",
    "    detection on different objects on two different scales. \n",
    "    Scales : Sizes of anchor boxes in terms of Height and Width\n",
    "    \n",
    "    Parameters:\n",
    "                num_extra_layers (int) : Number of convolutional layers added to the top of pretrained \n",
    "                                        convolutional base\n",
    "    Returning:\n",
    "                different_scales (list) : Different scales of the anchor boxes\n",
    "    \"\"\"\n",
    "    \n",
    "    scaling_factors = np.linspace(0.2,0.9,(num_extra_layers+2))\n",
    "    #The three different scales considered by our detection are given by:\n",
    "    #0.2 (the size of one anchor box will be 1/5th of the overall size of the image in both width and height)\n",
    "    #0.55 (the size of one anchor box will be almost 1/2 of the overall size of the image in both width and height)\n",
    "    #0.9 (the size of one anchor box will be 90 % of the overall size of the image in both width and height)\n",
    "    \n",
    "    different_scales = []\n",
    "    \n",
    "    for i in range(len(scaling_factors)-1):\n",
    "        scale = [scaling_factors[i],math.sqrt(scaling_factors[i]*scaling_factors[i+1])]\n",
    "        different_scales.append(scale)\n",
    "        \n",
    "    return different_scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_anchor_boxes(feature_map_shape,frame_shape,multiscale_index=0,num_extra_layers=2,\n",
    "                         aspect_ratios=[1,2,0.5]):\n",
    "    \"\"\"This function generates coordinates of anchor boxes on different aspect ratios for a given scale, \n",
    "    defined by the size of the feature map output by a specific convolutional layer (base or extra layer) \n",
    "    of the network.\n",
    "    \n",
    "    Parameters:\n",
    "                feature_map_shape(list or a tuple) : Shape of the feature map as a result of output from\n",
    "                                                     a convolutional layer\n",
    "                frame_shape (list or tuple) : Shape of the frame which is given as an input to the network\n",
    "                multiscale_index (int) : For which layer or scale of the convolutional layer, anchor boxes\n",
    "                                         need to be fetched\n",
    "                num_extra_layers (int) : Number of convolutional layers on the top of pretrained network\n",
    "                aspect_ratios (list) : Number of aspect ratios which need to be taken into consideration\n",
    "                                       for a specific scale of anchor boxes\n",
    "    Returning:\n",
    "                anchor_boxes_coords (tensor) : anchor boxes per feature map size as a result of output\n",
    "                                                  from the convolutional layer of the network\n",
    "    \"\"\"\n",
    "    #In order to generate anchor boxes for a specific convolutional layer (base layer or extra layer), \n",
    "    #first it's determined that what will be the scale of anchor boxes for that specific convolutional \n",
    "    #layer and then apply different aspect ratios on that scale.\n",
    "    \n",
    "    different_scales = generate_anchor_boxes_scales(num_extra_layers)\n",
    "    anchor_box_scale_per_layer = different_scales[multiscale_index]\n",
    "    \n",
    "    aspect_ratios_per_anchor_box = len(aspect_ratios) + 1\n",
    "    \n",
    "    frame_height,frame_width,_ = frame_shape\n",
    "    \n",
    "    feature_map_height,feature_map_width = feature_map_shape\n",
    "    \n",
    "    #Now, we are going to finally get the scaled dimensions of the input image according to the specific \n",
    "    #convolutional layer (or scale)\n",
    "    \n",
    "    scaled_height = frame_height * anchor_box_scale_per_layer[0]\n",
    "    scaled_width = frame_width * anchor_box_scale_per_layer[0]\n",
    "    \n",
    "    #Let's try to fetch different aspect ratio dimensions for the same scaled dimensions according to the \n",
    "    #specific convolutional layer\n",
    "    \n",
    "    all_aspect_ratios_per_scale = []\n",
    "    \n",
    "    for aspect_ratio in aspect_ratios:\n",
    "        aspect_ratiod_width = scaled_width * math.sqrt(aspect_ratio)\n",
    "        aspect_ratiod_height = scaled_height / math.sqrt(aspect_ratio)\n",
    "        all_aspect_ratios_per_scale.append([aspect_ratiod_width,aspect_ratiod_height])\n",
    "        \n",
    "    #Finally, we have added all the aspect ratios according to the specific scale except for the \n",
    "    #alternative aspect ratio for 1. So, let's add alternative aspect ratio for 1. \n",
    "    \n",
    "    aspect_ratiod_width = scaled_width * anchor_box_scale_per_layer[1]\n",
    "    aspect_ratiod_height = scaled_height * anchor_box_scale_per_layer[1]\n",
    "    all_aspect_ratios_per_scale.append([aspect_ratiod_width,aspect_ratiod_height])\n",
    "    \n",
    "    all_aspect_ratios_per_scale = np.array(all_aspect_ratios_per_scale)\n",
    "    \n",
    "    anchor_box_scale_width = frame_width / feature_map_width\n",
    "    anchor_box_scale_height = frame_height / feature_map_height\n",
    "    \n",
    "    #Let's see how anchor box coordinates will be stored in the form of a tensor\n",
    "    \n",
    "    #Let's first find the x coordinate position of the top most left feature map point\n",
    "    topmost_left_x = anchor_box_scale_width * 0.5\n",
    "    \n",
    "    #Let's now determine the x coordinate poistion of the top most right feature map point\n",
    "    topmost_right_x = (feature_map_width * anchor_box_scale_width) - (0.5 * anchor_box_scale_width)\n",
    "    \n",
    "    #let's create x coordinate positions of feature map points between top most left feature map point \n",
    "    #and top most right feature map point at equally spaced intervals of anchor box width\n",
    "    \n",
    "    cx = np.linspace(topmost_left_x,topmost_right_x,feature_map_width)\n",
    "    \n",
    "    #Let's first find the y coordinate position of the top most left feature map point\n",
    "    topmost_left_y = anchor_box_scale_height * 0.5\n",
    "    \n",
    "    #Let's now determine the y coordinate poistion of the top most right feature map point\n",
    "    topmost_right_y = (feature_map_height * anchor_box_scale_height) - (0.5 * anchor_box_scale_height)\n",
    "    \n",
    "    #let's create y coordinate positions of feature map points between top most left feature map point \n",
    "    #and top most right feature map point at equally spaced intervals of anchor box height\n",
    "    \n",
    "    cy = np.linspace(topmost_left_y,topmost_right_y,feature_map_height)\n",
    "    \n",
    "    cx_grid, cy_grid = np.meshgrid(cx,cy)\n",
    "    \n",
    "    cx_grid = np.expand_dims(cx_grid,axis=-1)\n",
    "    cy_grid = np.expand_dims(cy_grid,axis=-1)\n",
    "    \n",
    "    anchor_boxes_coords = np.zeros((feature_map_width,feature_map_height,\n",
    "                                       aspect_ratios_per_anchor_box,4))\n",
    "    \n",
    "    anchor_boxes_coords[:,:,:,0] = np.tile(cx_grid,reps=(1,1,aspect_ratios_per_anchor_box))\n",
    "    anchor_boxes_coords[:,:,:,1] = np.tile(cy_grid,reps=(1,1,aspect_ratios_per_anchor_box))\n",
    "    anchor_boxes_coords[:,:,:,2] = all_aspect_ratios_per_scale[:,0]\n",
    "    anchor_boxes_coords[:,:,:,3] = all_aspect_ratios_per_scale[:,1]\n",
    "    \n",
    "    return anchor_boxes_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corner_to_center(corner_coordinates):\n",
    "    \n",
    "    \"\"\"This function will convert corner format into center format.\n",
    "    That is from (xmin,xmax,ymin,ymax) to (cx,cy,w,h)\n",
    "    \n",
    "    Parameters:\n",
    "                corner_coordinates (tensor) : Coordinates of boxes in corner format\n",
    "    \n",
    "    Returning:\n",
    "                center_coordinates (tensor) : Coordinates of boxes in center format\n",
    "    \"\"\"\n",
    "    center_coordinates = np.copy(corner_coordinates).astype(np.float)\n",
    "    \n",
    "    center_coordinates[...,0] = 0.5 *(corner_coordinates[...,1] - corner_coordinates[...,0])\n",
    "    center_coordinates[...,0] = center_coordinates[...,0] + corner_coordinates[...,0]\n",
    "    center_coordinates[...,1] = 0.5 *(corner_coordinates[...,3] - corner_coordinates[...,2])\n",
    "    center_coordinates[...,1] = center_coordinates[...,1] + corner_coordinates[...,2]\n",
    "    \n",
    "    center_coordinates[...,2] = corner_coordinates[...,1] - corner_coordinates[...,0]\n",
    "    center_coordinates[...,3] = corner_coordinates[...,3] - corner_coordinates[...,2]\n",
    "    \n",
    "    return center_coordinates    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_to_corner(center_coordinates):\n",
    "    \n",
    "    \"\"\"This function will convert center format into corner format.\n",
    "    That is from (cx,cy,w,h) to (xmin,xmax,ymin,ymax)\n",
    "    \n",
    "    Parameters:\n",
    "                center_coordinates (tensor) : Coordinates of boxes in center format\n",
    "    \n",
    "    Returning:\n",
    "                corner_coordinates (tensor) : Coordinates of boxes in corner format\n",
    "    \"\"\"\n",
    "    \n",
    "    corner_coordinates = np.copy(center_coordinates).astype(np.float)\n",
    "    \n",
    "    corner_coordinates[...,0] = center_coordinates[...,0] - (0.5 * center_coordinates[...,2])\n",
    "    corner_coordinates[...,1] = center_coordinates[...,0] + (0.5 * center_coordinates[...,2])\n",
    "    corner_coordinates[...,2] = center_coordinates[...,1] - (0.5 * center_coordinates[...,3])\n",
    "    corner_coordinates[...,3] = center_coordinates[...,1] + (0.5 * center_coordinates[...,3])\n",
    "    \n",
    "    return corner_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_positive_anchor_boxes(iou,num_unique_categories,anchor_boxes_coords,gt_info,is_normalize=False,\n",
    "                                   iou_threshold=0.6):\n",
    "    \"\"\"A function to fetch all the positive anchor boxes which are having maximum amount of overlap (IoU)  \n",
    "    as well as IoU greater than a user configured IoU threshold (if provided by user) with ground truth \n",
    "    bounding boxes inside the frame(image). This function will calculate the normalized \n",
    "    (if is_normalize == True) offsets for all the positive anchor boxes as well as, it will also assign\n",
    "    the categories to all the positive anchor boxes which will be the categories of ground truth bounding\n",
    "    boxes.\n",
    "    \n",
    "    Parameters:\n",
    "                iou (tensor) : IoU of each anchor box with each Ground Truth bounding box\n",
    "                num_unique_categories (int) : Total number of categories in training data\n",
    "                anchor_boxes_coords (tensor) : anchor boxes coordinates per feature map\n",
    "                gt_info (tensor) : Ground truth bounding bounding box coordinates as well as class labels \n",
    "                                   of objects present in the image\n",
    "                is_normalize (bool) : Whether to use normalization on the offsets calculated for positive\n",
    "                                      anchor boxes or not.\n",
    "                iou_threshold (float) : If this value is less than 1 then the function will go for the \n",
    "                                        second round to find out extra positive anchor boxes apart from \n",
    "                                        the ones which it has already found out which were having maximum \n",
    "                                        iou with the ground truth bounding boxes.\n",
    "    Returning:\n",
    "                positive_anchor_boxes_categories (tensor) : Tensor of categories which have been assigned \n",
    "                                                            to all the positive anchor boxes\n",
    "                positive_anchor_boxes_offsets (tensor) : Normalized (if is_normalize == True) offsets for \n",
    "                                                         all the positive anchor boxes. \n",
    "                positive_anchor_boxes_indicator (tensor) : Tensor indicating which anchor boxes are marked\n",
    "                                                           as positive anchor boxes. \n",
    "    \"\"\"\n",
    "    #Let's first try to find out all the positive anchor boxes which have the highest IoU with\n",
    "    #ground truth bounding boxes among all the anchor boxes having different aspect ratios for a \n",
    "    #specific scale. \n",
    "    max_iou_anchor_boxes = np.argmax(iou,axis=0)\n",
    "    \n",
    "    #if the IoU threshold is less than 1 then we will go for second round of selection of credible positive\n",
    "    #anchor boxes whicn have IoU with ground truth bounding boxes greater than the user selected IoU. \n",
    "    if iou_threshold < 1.0:\n",
    "        secondary_pos_anchor_boxes = np.argwhere(iou > iou_threshold)\n",
    "        \n",
    "        #If we are getting some number of secondary positive anchor boxes then we have to determien their \n",
    "        #offsets as well as class labels (ground truth information). \n",
    "        if secondary_pos_anchor_boxes.size > 0:\n",
    "            \n",
    "            secondary_anchor_boxes = secondary_pos_anchor_boxes[:,0]\n",
    "            secondary_anchor_boxes_categories = secondary_pos_anchor_boxes[:,1]\n",
    "            \n",
    "            secondary_anchor_boxes_gt_info = gt_info[secondary_anchor_boxes_categories]\n",
    "            \n",
    "            #Collecting all the primary as well as the secondary positive anchor boxes over an image\n",
    "            all_positive_anchor_boxes = np.concatenate([max_iou_anchor_boxes,secondary_anchor_boxes],axis=0)\n",
    "            \n",
    "            #Collecting the ground truth bounding box coordinates as well as ground truth class labels for \n",
    "            #all the positive anchor boxes to calculate the offsets for all the positive anchor boxes. \n",
    "            all_positive_anchor_boxes_gt_info = np.concatenate([gt_info,secondary_anchor_boxes_gt_info],\n",
    "                                                               axis=0)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            #If we didn't get any secondary positive anchor boxes while comparing with IoU threshold then\n",
    "            # our all positive anchor boxes will be simply primary anchor boxes (max_iou_anchor_boxes)\n",
    "            all_positive_anchor_boxes = max_iou_anchor_boxes\n",
    "            \n",
    "            #If we didn't get any secondary positive anchor boxes while comparing with IoU threshold then\n",
    "            #the gt_info of all positive anchor boxes will be equal to the gt_info of all the primary anchor \n",
    "            #boxes\n",
    "            all_positive_anchor_boxes_gt_info = gt_info\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        all_positive_anchor_boxes = max_iou_anchor_boxes\n",
    "        all_positive_anchor_boxes_gt_info = gt_info\n",
    "        \n",
    "    #The below tensor of positive anchor boxes indicator will be used during the calculation of Regression\n",
    "    #loss while determining that which anchor boxes are positive anchor boxes because only for those\n",
    "    #positive anchor boxes, the regression loss will be computed. \n",
    "    positive_anchor_boxes_indicator = np.zeros((iou.shape[0],4))\n",
    "    \n",
    "    #The tensor below is acting as a mask just like a boolean mask which will make the contribution of\n",
    "    #all negative anchor boxes towards the regression loss (whether smooth L1 or L2 loss) zero and only \n",
    "    #all positive anchor boxes will be considered during computation because for them, there will be ones\n",
    "    #at all the four places corresponsing to offsets. \n",
    "    positive_anchor_boxes_indicator[all_positive_anchor_boxes] = 1.0\n",
    "        \n",
    "    positive_anchor_boxes_categories = np.zeros((iou.shape[0],num_unique_categories))\n",
    "    \n",
    "    #Initially, all the anchor boxes for a specific scale will be assigned the category of background\n",
    "    positive_anchor_boxes_categories[:,0] = 1\n",
    "    \n",
    "    #Then all the positive anchor boxes will be assigned to the specific object categories based on the \n",
    "    #category of that ground truth bounding box with which the IoU is maximum or greater than a specific\n",
    "    #threshold.\n",
    "    positive_anchor_boxes_categories[all_positive_anchor_boxes,0] = 0\n",
    "    \n",
    "    all_positive_anchor_boxes = all_positive_anchor_boxes.reshape(all_positive_anchor_boxes.shape[0],1)\n",
    "    all_positive_anchor_boxes_categories = all_positive_anchor_boxes_gt_info[:,4].reshape(\n",
    "                                            all_positive_anchor_boxes_gt_info.shape[0],1).astype(int)\n",
    "    \n",
    "    row_col = np.append(all_positive_anchor_boxes,all_positive_anchor_boxes_categories,axis=1)\n",
    "    positive_anchor_boxes_categories[row_col[:,0],row_col[:,1]] = 1\n",
    "    \n",
    "    positive_anchor_boxes_offsets = np.zeros((iou.shape[0],4))\n",
    "    \n",
    "    if is_normalize == True:\n",
    "        \n",
    "        all_positive_anchor_boxes_gt_info = corner_to_center(all_positive_anchor_boxes_gt_info)\n",
    "        anchor_boxes_coords = corner_to_center(anchor_boxes_coords)\n",
    "        \n",
    "        offsets_xy = all_positive_anchor_boxes_gt_info[:,0:2] - anchor_boxes_coords[all_positive_anchor_boxes[:,0],0:2]\n",
    "        offsets_xy = offsets_xy/anchor_boxes_coords[all_positive_anchor_boxes[:,0],2:4]\n",
    "        offsets_xy = offsets_xy/0.1\n",
    "        \n",
    "        offsets_wh = np.log(all_positive_anchor_boxes_gt_info[:,2:4]/anchor_boxes_coords[all_positive_anchor_boxes[:,0],2:4])\n",
    "        offsets_wh = offsets_wh/0.2\n",
    "        \n",
    "        offsets = np.concatenate([offsets_xy,offsets_wh],axis=1)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        offsets = all_positive_anchor_boxes_gt_info[:,0:4] - anchor_boxes_coords[all_positive_anchor_boxes[:,0]]\n",
    "        \n",
    "    positive_anchor_boxes_offsets[all_positive_anchor_boxes[:,0]] = offsets\n",
    "    \n",
    "    return positive_anchor_boxes_categories,positive_anchor_boxes_offsets,positive_anchor_boxes_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(bboxes1,bboxes2):\n",
    "    \"\"\"This function will calculate the intersection between batches of two different boxes.\n",
    "    \n",
    "    Parameters:\n",
    "                bboxes1 (tensor) : Batch of first bounding box coordinates\n",
    "                bboxes2 (tensor) : Batch of second bounding box coordinates\n",
    "                \n",
    "    Returning:\n",
    "                intersection_area (tensor) : intersection of areas bounded between batch of first bounding \n",
    "                                            box and second bounding box coordinates. \n",
    "    \"\"\"\n",
    "    #Let's try to find out that how many bounding boxes are there in the batch of first bounding boxes\n",
    "    batch1 = bboxes1.shape[0]\n",
    "    batch2 = bboxes2.shape[0]\n",
    "    \n",
    "    bboxes1_topmost_left_corner = np.expand_dims(bboxes1[:,[0,2]],axis=1)\n",
    "    bboxes1_topmost_left_corner = np.tile(bboxes1_topmost_left_corner,reps=(1,batch2,1))\n",
    "    \n",
    "    bboxes2_topmost_left_corner = np.expand_dims(bboxes2[:,[0,2]],axis=0)\n",
    "    bboxes2_topmost_left_corner = np.tile(bboxes2_topmost_left_corner,reps=(batch1,1,1))\n",
    "    \n",
    "    min_topmost_left = np.maximum(bboxes1_topmost_left_corner,bboxes2_topmost_left_corner)\n",
    "    \n",
    "    bboxes1_bottommost_right_corner = np.expand_dims(bboxes1[:,[1,3]],axis=1)\n",
    "    bboxes1_bottommost_right_corner = np.tile(bboxes1_bottommost_right_corner,reps=(1,batch2,1))\n",
    "    \n",
    "    bboxes2_bottommost_right_corner = np.expand_dims(bboxes2[:,[1,3]],axis=0)\n",
    "    bboxes2_bottommost_right_corner = np.tile(bboxes2_bottommost_right_corner,reps=(batch1,1,1))\n",
    "    \n",
    "    max_bottommost_right = np.minimum(bboxes1_bottommost_right_corner,bboxes2_bottommost_right_corner)\n",
    "    \n",
    "    wh = np.maximum(0,(max_bottommost_right - min_topmost_left))\n",
    "    \n",
    "    intersection_area = wh[:,:,0] * wh[:,:,1]\n",
    "    \n",
    "    return intersection_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union(bboxes1,bboxes2):\n",
    "    \"\"\"This function will calculate the union areas between batches of two different boxes. \n",
    "    \n",
    "     Parameters:\n",
    "                bboxes1 (tensor) : Batch of first bounding box coordinates\n",
    "                bboxes2 (tensor) : Batch of second bounding box coordinates\n",
    "                \n",
    "    Returning:\n",
    "                union_area (tensor) : union of areas of batch of first bounding \n",
    "                                      box and second bounding box coordinates. \n",
    "    \"\"\"\n",
    "    #Let's try to find out that how many bounding boxes are there in the batch of first bounding boxes\n",
    "    batch1 = bboxes1.shape[0]\n",
    "    batch2 = bboxes2.shape[0]\n",
    "    \n",
    "    bboxes1_width = bboxes1[:,1] - bboxes1[:,0]\n",
    "    bboxes1_height = bboxes1[:,3] - bboxes1[:,2]\n",
    "    \n",
    "    bboxes1_area = bboxes1_width * bboxes1_height\n",
    "    bboxes1_area = np.expand_dims(bboxes1_area,axis=1)\n",
    "    bboxes1_area = np.tile(bboxes1_area, reps=(1,batch2))\n",
    "    \n",
    "    bboxes2_width = bboxes2[:,1] - bboxes2[:,0]\n",
    "    bboxes2_height = bboxes2[:,3] - bboxes2[:,2]\n",
    "    \n",
    "    bboxes2_area = bboxes2_width * bboxes2_height\n",
    "    bboxes2_area = np.expand_dims(bboxes2_area,axis=0)\n",
    "    bboxes2_area = np.tile(bboxes2_area, reps=(batch1,1))\n",
    "    \n",
    "    union_area = (bboxes1_area + bboxes2_area) - intersection(bboxes1,bboxes2)\n",
    "    \n",
    "    return union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(bboxes1,bboxes2):\n",
    "    \"\"\"This function calculates the IoU between the batches of two different types of bounding boxes. \n",
    "     Parameters:\n",
    "                bboxes1 (tensor) : Batch of first bounding box coordinates\n",
    "                bboxes2 (tensor) : Batch of second bounding box coordinates\n",
    "                \n",
    "    Returning:\n",
    "                iou_area (tensor) : Intersection over Union of areas of between batch of first and\n",
    "                                    second group of bounding box coordinates. \n",
    "    \"\"\"\n",
    "    intersection_areas = intersection(bboxes1,bboxes2)\n",
    "    union_areas = union(bboxes1,bboxes2)\n",
    "    return intersection_areas/union_areas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
