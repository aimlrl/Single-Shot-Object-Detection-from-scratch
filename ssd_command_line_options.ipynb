{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "AfPQBpspaw9E",
    "outputId": "5f10762f-9345-4451-d77a-dbe4d2d175ce"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from convolutional_base_options import create_resnet\n",
    "import object_detection_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch):\n",
    "    \n",
    "    \"\"\"Function to implement learning rate scheduler to be used in Keras's builtin or Custom Callbacks\"\"\"\n",
    "    \n",
    "    lr = 1e-3\n",
    "    epoch_offset = object_detection_config.params['epoch_offset']\n",
    "    if epoch > (200 - epoch_offset):\n",
    "        lr *= 1e-4\n",
    "    elif epoch > (180 - epoch_offset):\n",
    "        lr *= 5e-4\n",
    "    elif epoch > (160 - epoch_offset):\n",
    "        lr *= 1e-3\n",
    "    elif epoch > (140 - epoch_offset):\n",
    "        lr *= 5e-3\n",
    "    elif epoch > (120 - epoch_offset):\n",
    "        lr *= 1e-2\n",
    "    elif epoch > (100 - epoch_offset):\n",
    "        lr *= 5e-2\n",
    "    elif epoch > (80 - epoch_offset):\n",
    "        lr *= 1e-1\n",
    "    elif epoch > (60 - epoch_offset):\n",
    "        lr *= 5e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FkDeHyZndRji"
   },
   "outputs": [],
   "source": [
    "def our_ssd_cnn_parser():\n",
    "\n",
    "    \"\"\"Instatiate a command line parser for building, training, and testing of ssd network model\"\"\"\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Object detection using SSD')\n",
    "    # arguments for model building and training\n",
    "    desc = \"Number of extra layers in the SSD CNN after the prebuilt or custom resnet first stage convolutional base\"\n",
    "    parser.add_argument(\"--num_extra_layers\",default=2,type=int,help=desc)\n",
    "    \n",
    "    desc = \"Batch size to be used during training of SSD CNN\"\n",
    "    parser.add_argument(\"--batch_size\",default=2,type=int,help=desc)\n",
    "    \n",
    "    desc = \"Number of epochs to train SSD CNN\"\n",
    "    parser.add_argument(\"--epochs\",default=50,type=int,help=desc)\n",
    "    \n",
    "    desc = \"Number of data generator worker threads\"\n",
    "    parser.add_argument(\"--workers\",default=3,type=int,help=desc)\n",
    "    \n",
    "    desc = \"IoU threshold to be used in second round for fetching more positive anchor boxes\"\n",
    "    parser.add_argument(\"--iou_threshold\",default=0.6,type=float,help=desc)\n",
    "    \n",
    "    desc = \"Convolutional base of the first stage to be used in the SSD CNN\"\n",
    "    parser.add_argument(\"--conv_base\",default=create_resnet,help=desc)\n",
    "    \n",
    "    desc = \"Will train the model\"\n",
    "    parser.add_argument(\"--train\",action='store_true',help=desc)\n",
    "    \n",
    "    desc = \"Print model summary (text and png)\"\n",
    "    parser.add_argument(\"--summary\",default=False,action='store_true',help=desc)\n",
    "    \n",
    "    desc = \"Use categorical focal and smooth L1 loss functions\"\n",
    "    parser.add_argument(\"--improved-loss\",default=False,action='store_true',help=desc)\n",
    "    \n",
    "    desc = \"Use smooth L1 loss function\"\n",
    "    parser.add_argument(\"--smooth-l1\",default=False,action='store_true',help=desc)\n",
    "    \n",
    "    desc = \"Use normalized predictions\"\n",
    "    parser.add_argument(\"--is_normalize\",default=False,action='store_true',help=desc)\n",
    "    \n",
    "    desc = \"Directory for saving files\"\n",
    "    parser.add_argument(\"--save-dir\",default=\"weights\",help=desc)\n",
    "    \n",
    "    desc = \"Dataset used to train the SSD CNN\"\n",
    "    parser.add_argument(\"--dataset\",default=\"ExDark\",help=desc)\n",
    "\n",
    "    # inputs configurations\n",
    "    desc = \"Input image height\"\n",
    "    parser.add_argument(\"--height\",default=500,type=int,help=desc)\n",
    "    \n",
    "    desc = \"Input image width\"\n",
    "    parser.add_argument(\"--width\",default=375,type=int,help=desc)\n",
    "    \n",
    "    desc = \"Input image channels\"\n",
    "    parser.add_argument(\"--channels\",default=3,type=int,help=desc)\n",
    "\n",
    "    # dataset configurations\n",
    "    desc = \"Path to dataset directory\"\n",
    "    parser.add_argument(\"--data_path\",default=\"dataset/ExDark\",help=desc)\n",
    "    \n",
    "    desc = \"Train labels csv file name\"\n",
    "    parser.add_argument(\"--train-labels\",default=\"training_data_gt_labels.csv\",help=desc)\n",
    "    \n",
    "    desc = \"Test labels csv file name\"\n",
    "    parser.add_argument(\"--test-labels\",default=\"testing_data_gt_labels.csv\",help=desc)\n",
    "\n",
    "    # configurations for evaluation of a trained model\n",
    "    desc = \"Load h5 model trained weights\"\n",
    "    parser.add_argument(\"--restore_weights\",help=desc)\n",
    "    \n",
    "    desc = \"Evaluate model\"\n",
    "    parser.add_argument(\"--evaluate\",default=False,action='store_true',help=desc)\n",
    "    \n",
    "    desc = \"Image for evaluation\"\n",
    "    parser.add_argument(\"--image-file\",default=None,help=desc)\n",
    "    \n",
    "    desc = \"Class posterior probability threshold while applying NMS over the predictions of a network\"\n",
    "    parser.add_argument(\"--posterior_prob_threshold\",default=0.5,type=float,help=desc)\n",
    "    \n",
    "    desc = \"IoU threshold while performing NMS\"\n",
    "    parser.add_argument(\"--nms_iou_threshold\",default=0.2,type=float,help=desc)\n",
    "    \n",
    "    return parser"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ssd_command_line_options.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
